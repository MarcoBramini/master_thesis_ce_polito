2023-11-01 23:35:34,892 - main - INFO - PyTorch is currently running on: cuda
2023-11-01 23:35:34,895 - main - INFO - Initial parameters: {'n_population': 256, 'tau_mem': 0.129, 'tau_syn': 0.092}
2023-11-01 23:35:38,615 - main - INFO - Loaded 30111 events from file ../data/4bit_spikeset_PHASE_full.npy
2023-11-01 23:35:38,680 - main - INFO - Generated events partitions: train(18066), val(6022, test(6023))
2023-11-01 23:35:38,717 - main - INFO - Built network: 
TorchSequential  with shape (12, 3) {
    LinearTorch '0_LinearTorch' with shape (12, 256)
    LIFTorch '1_LIFTorch' with shape (256, 256)
    TorchResidual '2_TorchResidual' with shape (256, 256) {
        LinearTorch '0_LinearTorch' with shape (256, 256)
        LIFTorch '1_LIFTorch' with shape (256, 256)
    }
    TorchResidual '3_TorchResidual' with shape (256, 256) {
        LinearTorch '0_LinearTorch' with shape (256, 256)
        LIFTorch '1_LIFTorch' with shape (256, 256)
    }
    LinearTorch '4_LinearTorch' with shape (256, 3)
    LIFTorch '5_LIFTorch' with shape (3, 3)
}
2023-11-01 23:35:40,181 - main - INFO - Dropped 193 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:35:40,197 - main - INFO - Dropped 193 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:35:40,213 - main - INFO - Dropped 193 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:35:47,072 - main - INFO - Epoch 0 -> Loss:1.1281745223438038, Acc:0.3444038525406842, Best Acc:0.3444038525406842
2023-11-01 23:36:39,880 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:36:39,892 - main - INFO - Dropped 186 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:36:39,906 - main - INFO - Dropped 186 output synapses each for 251 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:37:39,213 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:37:39,225 - main - INFO - Dropped 189 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:37:39,240 - main - INFO - Dropped 189 output synapses each for 253 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:38:38,287 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:38:38,300 - main - INFO - Dropped 190 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:38:38,314 - main - INFO - Dropped 190 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:39:37,460 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:39:37,472 - main - INFO - Dropped 191 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:39:37,486 - main - INFO - Dropped 190 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:40:36,706 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:40:36,720 - main - INFO - Dropped 192 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:40:36,736 - main - INFO - Dropped 191 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:41:36,037 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:41:36,049 - main - INFO - Dropped 192 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:41:36,065 - main - INFO - Dropped 191 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:42:34,944 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:42:34,956 - main - INFO - Dropped 192 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:42:34,974 - main - INFO - Dropped 191 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:43:33,939 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:43:33,951 - main - INFO - Dropped 192 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:43:33,965 - main - INFO - Dropped 191 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:44:32,925 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:44:32,939 - main - INFO - Dropped 192 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:44:32,955 - main - INFO - Dropped 192 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:45:31,856 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:45:31,867 - main - INFO - Dropped 192 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:45:31,884 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:45:37,843 - main - INFO - Epoch 100 -> Loss:0.877873091136708, Acc:0.6157422783128529, Best Acc:0.6539355695782133
2023-11-01 23:46:30,814 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:46:30,828 - main - INFO - Dropped 192 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:46:30,844 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:47:29,909 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:47:29,921 - main - INFO - Dropped 192 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:47:29,942 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:48:29,135 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:48:29,148 - main - INFO - Dropped 192 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:48:29,164 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:49:28,287 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:49:28,299 - main - INFO - Dropped 192 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:49:28,313 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:50:27,704 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:50:27,717 - main - INFO - Dropped 192 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:50:27,734 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:51:26,986 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:51:26,998 - main - INFO - Dropped 192 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:51:27,013 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:52:26,219 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:52:26,231 - main - INFO - Dropped 192 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:52:26,245 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:53:20,070 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:53:20,082 - main - INFO - Dropped 192 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:53:20,097 - main - INFO - Dropped 192 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:54:18,281 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:54:18,293 - main - INFO - Dropped 192 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:54:18,307 - main - INFO - Dropped 192 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:55:16,986 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:55:16,999 - main - INFO - Dropped 192 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:55:17,015 - main - INFO - Dropped 192 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:55:22,962 - main - INFO - Epoch 200 -> Loss:0.6381070929415086, Acc:0.6919628030554633, Best Acc:0.7002656924609765
2023-11-01 23:56:15,945 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:56:15,958 - main - INFO - Dropped 192 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:56:15,974 - main - INFO - Dropped 192 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:57:14,940 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:57:14,954 - main - INFO - Dropped 192 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:57:14,970 - main - INFO - Dropped 192 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:58:13,798 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:58:13,810 - main - INFO - Dropped 192 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:58:13,824 - main - INFO - Dropped 192 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:59:12,488 - main - INFO - Dropped 147 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-01 23:59:12,502 - main - INFO - Dropped 192 output synapses each for 204 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-01 23:59:12,518 - main - INFO - Dropped 192 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 00:00:11,576 - main - INFO - Training finished with accuracy: 0.7150448356027899
