2023-11-07 02:31:39,819 - main - INFO - PyTorch is currently running on: cuda
2023-11-07 02:31:39,822 - main - INFO - Initial parameters: {'n_population': 256, 'tau_mem': 0.163, 'tau_syn': 0.078}
2023-11-07 02:31:44,695 - main - INFO - Loaded 41223 events from file ../data/4bit_spikeset_PHASE_full.npy
2023-11-07 02:31:44,783 - main - INFO - Generated events partitions: train(24733), val(8245, test(8245))
2023-11-07 02:31:44,825 - main - INFO - Built network: 
TorchSequential  with shape (12, 4) {
    LinearTorch '0_LinearTorch' with shape (12, 256)
    LIFTorch '1_LIFTorch' with shape (256, 256)
    TorchResidual '2_TorchResidual' with shape (256, 256) {
        LinearTorch '0_LinearTorch' with shape (256, 256)
        LIFTorch '1_LIFTorch' with shape (256, 256)
    }
    TorchResidual '3_TorchResidual' with shape (256, 256) {
        LinearTorch '0_LinearTorch' with shape (256, 256)
        LIFTorch '1_LIFTorch' with shape (256, 256)
    }
    LinearTorch '4_LinearTorch' with shape (256, 4)
    LIFTorch '5_LIFTorch' with shape (4, 4)
}
2023-11-07 02:31:46,256 - main - INFO - Dropped 193 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 02:31:46,272 - main - INFO - Dropped 193 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:31:46,288 - main - INFO - Dropped 193 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:31:55,749 - main - INFO - Epoch 0 -> Loss:1.387495959798495, Acc:0.25627653123104915, Best Acc:0.25627653123104915
2023-11-07 02:33:10,367 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 02:33:10,381 - main - INFO - Dropped 180 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:33:10,397 - main - INFO - Dropped 183 output synapses each for 252 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:34:34,087 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 02:34:34,100 - main - INFO - Dropped 186 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:34:34,116 - main - INFO - Dropped 188 output synapses each for 252 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:35:57,848 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 02:35:57,860 - main - INFO - Dropped 187 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:35:57,874 - main - INFO - Dropped 189 output synapses each for 252 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:37:20,936 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 02:37:20,948 - main - INFO - Dropped 189 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:37:20,963 - main - INFO - Dropped 189 output synapses each for 253 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:38:44,202 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 02:38:44,216 - main - INFO - Dropped 189 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:38:44,232 - main - INFO - Dropped 189 output synapses each for 253 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:40:06,766 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 02:40:06,778 - main - INFO - Dropped 189 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:40:06,794 - main - INFO - Dropped 190 output synapses each for 253 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:41:29,470 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 02:41:29,482 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:41:29,508 - main - INFO - Dropped 190 output synapses each for 253 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:42:51,903 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 02:42:51,916 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:42:51,931 - main - INFO - Dropped 190 output synapses each for 253 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:44:08,261 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 02:44:08,275 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:44:08,294 - main - INFO - Dropped 190 output synapses each for 253 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:45:31,348 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 02:45:31,361 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:45:31,375 - main - INFO - Dropped 190 output synapses each for 253 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:45:39,819 - main - INFO - Epoch 100 -> Loss:1.0893478492895763, Acc:0.5507580351728321, Best Acc:0.5507580351728321
2023-11-07 02:46:54,528 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 02:46:54,542 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:46:54,558 - main - INFO - Dropped 190 output synapses each for 253 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:48:17,353 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 02:48:17,367 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:48:17,384 - main - INFO - Dropped 190 output synapses each for 253 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:49:40,249 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 02:49:40,263 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:49:40,279 - main - INFO - Dropped 190 output synapses each for 253 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:51:02,649 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 02:51:02,662 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:51:02,678 - main - INFO - Dropped 190 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:52:25,463 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 02:52:25,477 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:52:25,493 - main - INFO - Dropped 190 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:53:48,675 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 02:53:48,689 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:53:48,705 - main - INFO - Dropped 190 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:55:11,692 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 02:55:11,704 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:55:11,719 - main - INFO - Dropped 190 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:56:34,920 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 02:56:34,933 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:56:34,949 - main - INFO - Dropped 190 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:57:57,713 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 02:57:57,726 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:57:57,742 - main - INFO - Dropped 190 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:59:20,734 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 02:59:20,746 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:59:20,760 - main - INFO - Dropped 190 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 02:59:29,112 - main - INFO - Epoch 200 -> Loss:1.0162598292032878, Acc:0.5482110369921165, Best Acc:0.5710127349909035
2023-11-07 03:00:43,618 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 03:00:43,632 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 03:00:43,649 - main - INFO - Dropped 190 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 03:02:06,681 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 03:02:06,693 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 03:02:06,710 - main - INFO - Dropped 190 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 03:03:29,703 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 03:03:29,715 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 03:03:29,729 - main - INFO - Dropped 190 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 03:04:52,589 - main - INFO - Dropped 150 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-07 03:04:52,603 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 03:04:52,617 - main - INFO - Dropped 191 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-07 03:06:15,653 - main - INFO - Training finished with accuracy: 0.5804730139478472
