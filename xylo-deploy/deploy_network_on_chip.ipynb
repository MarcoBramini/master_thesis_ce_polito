{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import torch\n",
    "\n",
    "# - Rockpool imports\n",
    "from rockpool.parameters import Constant\n",
    "from rockpool.timeseries import TSEvent\n",
    "from rockpool.transform import quantize_methods as q\n",
    "\n",
    "# - Modules required to interface and deploy models to the Xylo-IMU HDK\n",
    "from rockpool.devices.xylo import find_xylo_hdks\n",
    "from rockpool.devices.xylo.syns61201 import XyloSamna, config_from_specification, mapper, XyloSim\n",
    "#from rockpool.devices.xylo.syns63300 import XyloSamna, config_from_specification, mapper, XyloSim\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../training-pipeline/lib\")\n",
    "from data_loading import load_data\n",
    "from xylo_net_adaptation import net_from_params, adapt_network\n",
    "import xylo_networks as xylo_networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Model Restoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "model_path = \"../nni_experiments/xylo/final/xylo_7cb_ff_deep_deep_res\"\n",
    "\n",
    "def load_data_from_model_path(model_path):\n",
    "    # Obtain training metadata\n",
    "    training_metadata = None\n",
    "    with open(f\"{model_path}/training_metadata.json\") as f:\n",
    "        training_metadata = json.load(f)\n",
    "\n",
    "    # Load dataset\n",
    "    input_params = training_metadata[\"input_params\"]\n",
    "\n",
    "    train_dl, val_dl, test_dl = load_data(**input_params)\n",
    "    return train_dl, val_dl, test_dl, input_params\n",
    "\n",
    "\n",
    "def load_model_from_path(model_path, dt):\n",
    "    # Obtain neuron parameters\n",
    "    model_metadata = None\n",
    "    with open(f\"{model_path}/model_metadata.json\") as f:\n",
    "        model_metadata = json.load(f)\n",
    "\n",
    "    neuron_parameters = {\n",
    "        \"tau_mem\": model_metadata[\"params\"][\"tau_mem\"],\n",
    "        \"tau_syn\": model_metadata[\"params\"][\"tau_syn\"],\n",
    "        \"bias\": Constant(0.0),\n",
    "        \"threshold\": Constant(1.0),\n",
    "        \"dt\": dt,\n",
    "    }\n",
    "\n",
    "    # Build network from model parameters\n",
    "    model_params = None\n",
    "    with open(f\"{model_path}/model_params\") as f:\n",
    "        model_params = json.load(f)\n",
    "\n",
    "    net = net_from_params(model_params, neuron_parameters)\n",
    "\n",
    "    print(f\"Built network: \\n\\t{net}\")\n",
    "\n",
    "    # Load network parameters\n",
    "    net.load(f\"{model_path}/model_params\")\n",
    "\n",
    "    # Adapt network to be compatible with and deployable on Xylo\n",
    "    adapt_network(net, max_synapses=62)\n",
    "\n",
    "    return net\n",
    "\n",
    "train_dl, val_dl, test_dl, input_params = load_data_from_model_path(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load network from model path\n",
    "net = load_model_from_path(model_path, input_params[\"dt\"])\n",
    "\n",
    "# Evaluate network on the full test set\n",
    "net.eval()\n",
    "ds = test_dl.dataset\n",
    "with torch.no_grad():\n",
    "    output, _, _ = net(ds.x)\n",
    "    preds = output.sum(dim=1).argmax(dim=1)\n",
    "    print(f\"Final accuracy: {torch.round(torch.mean(preds == ds.y, dtype=float)*100,decimals=2)}%\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(ds.y, preds)\n",
    "disp = ConfusionMatrixDisplay(cm)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(ds.y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the network activity for a specific sample\n",
    "net.eval()\n",
    "ds = test_dl.dataset\n",
    "i = 1\n",
    "with torch.no_grad():\n",
    "    output, _, b = net(ds.x[i])\n",
    "\n",
    "    spks = torch.sum(output,dim=1)\n",
    "    print(f\"Neural Activity (spikes per neuron): {spks.numpy()[0]}\")\n",
    "    print(f\"Expected Label: {int(ds.y[i])}\")\n",
    "    print(f\"Predicted Label: {spks.argmax()}\")\n",
    "\n",
    "    TSEvent.from_raster(\n",
    "                output[0].detach().numpy(),\n",
    "                dt=5e-2,\n",
    "            ).plot(marker=\"|\", s=8)\n",
    "    plt.plot(0, ds.y[i], '>', ms=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization Tuning and Hardware Config Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load network from model path\n",
    "net = load_model_from_path(model_path, input_params[\"dt\"])\n",
    "\n",
    "# Convert network to spec\n",
    "spec = mapper(net.as_graph(), weight_dtype='float', threshold_dtype='float', dash_dtype='float')\n",
    "spec_Q = copy.deepcopy(spec)\n",
    "\n",
    "# Use quantization tuned specification object, if available\n",
    "try:\n",
    "    with open(f\"{model_path}/xylo_qtuned_params\", \"rb\") as f:\n",
    "        params_Q = pickle.load(f)\n",
    "        spec_Q.update(params_Q)\n",
    "    print(\"Model tuning applied\")\n",
    "except FileNotFoundError:\n",
    "    # Quantize the parameters\n",
    "    spec_Q.update(q.global_quantize(**spec_Q))\n",
    "    print(\"No model tuning available\")\n",
    "\n",
    "#TODO: add reference to github issue\n",
    "if spec_Q[\"dash_syn\"][0] == 0:\n",
    "    spec_Q[\"dash_syn\"] += 1\n",
    "if spec_Q[\"dash_syn_out\"][0] == 0:\n",
    "    spec_Q[\"dash_syn_out\"] += 1\n",
    "\n",
    "# Convert spec to Xylo configuration\n",
    "config, is_valid, m = config_from_specification(**spec_Q)\n",
    "if not is_valid:\n",
    "    raise ValueError(f\"Error detected in spec:\\n{m}\")\n",
    "else:\n",
    "    print(\"ok\")\n",
    "\n",
    "# Build XyloSim from the config\n",
    "mod = XyloSim.from_config(config, dt = input_params[\"dt\"])\n",
    "print(mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantized Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Display the quantized network weights\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(abs(spec['weights_in'].T), cmap=\"hot\")\n",
    "plt.title('$W_{in}$')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(abs(spec['weights_rec'].T), cmap=\"hot\")\n",
    "plt.title('$W_{rec}$')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(abs(spec['weights_out'].T), cmap=\"hot\")\n",
    "plt.title('$W_{out}$');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the XyloSim network on the full test set\n",
    "ds = test_dl.dataset\n",
    "preds = []\n",
    "scores = []\n",
    "for x,y in zip(ds.x,ds.y):\n",
    "    output, _, rec = mod(x.numpy())\n",
    "    pred = np.sum(output,axis=0)\n",
    "    preds.append(np.argmax(pred))\n",
    "    scores.append(np.argmax(pred) == y.numpy())\n",
    "\n",
    "acc = np.sum(scores)/len(scores)\n",
    "\n",
    "print(f\"Final accuracy: {np.round(acc, decimals=4)*100}%\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(ds.y, preds)\n",
    "disp = ConfusionMatrixDisplay(cm)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(ds.y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the XyloSim network activity for a specific sample\n",
    "ds = test_dl.dataset\n",
    "i = 1\n",
    "\n",
    "output, _, rec = mod(ds.x[i].numpy(),record=True)\n",
    "\n",
    "spks = np.sum(output,axis=0)\n",
    "pred = np.argmax(spks)\n",
    "print(f\"Readout layer activity (spikes): {spks}\")\n",
    "print(f\"Label: {int(ds.y[i])}\")\n",
    "print(f\"Prediction: {pred}\")\n",
    "\n",
    "TSEvent.from_raster(\n",
    "            output,\n",
    "            dt=input_params[\"dt\"],\n",
    "        ).plot(marker=\"|\", s=8)\n",
    "plt.plot(0.01, ds.y[i], '>', ms=10, color='g')\n",
    "plt.plot(0.01, pred, '>', ms=10, color='r')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "times = np.arange(output.shape[0]) * input_params[\"dt\"]\n",
    "plt.plot(times, rec['Vmem_out'])\n",
    "plt.legend(range(0,7))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Xylo Hardware Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISCLAIMER:THE FOLLOWING CODE IS FOR A XYLO IMU BOARD, NOT THE XYLO AUDIO ADDRESSED BY THIS THESIS\n",
    "devices, modules, vers = find_xylo_hdks()\n",
    "print(devices, vers)\n",
    "\n",
    "found_device = None\n",
    "for i,d in enumerate(devices):\n",
    "    if vers[i] == \"syns63300\":\n",
    "        found_device = d\n",
    "        found_device_module = modules[i]\n",
    "\n",
    "if found_device == None:\n",
    "    raise ValueError(\"No Xylo found\")\n",
    "\n",
    "print(f'Setting Xylo main clock to {found_device_module.xylo_imu_devkit_utils.set_xylo_core_clock_freq(found_device, 15)} MHz')\n",
    "mod_hdk = XyloSamna(found_device, config, input_params[\"dt\"],power_frequency=20.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Xylo network on the full test set\n",
    "ds = test_dl.dataset\n",
    "preds = []\n",
    "scores = []\n",
    "for i,(x,y) in list(enumerate(zip(ds.x,ds.y)))[0:100]:\n",
    "    output, _, rec = mod_hdk.evolve(x.numpy().astype(int),record=True)\n",
    "    pred = np.sum(output,axis=0)\n",
    "    preds.append(np.argmax(pred))\n",
    "    scores.append(np.argmax(pred) == y.numpy())\n",
    "\n",
    "acc = np.sum(scores)/len(scores)\n",
    "\n",
    "print(f\"Final accuracy: {np.round(acc, decimals=4)*100}%\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(ds.y[0:100], preds)\n",
    "disp = ConfusionMatrixDisplay(cm)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(ds.y[0:100], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the XyloSim network activity for a specific sample\n",
    "ds = test_dl.dataset\n",
    "i = 1\n",
    "\n",
    "output, _, rec = mod_hdk.evolve(ds.x[i].numpy().astype(int),record=True,record_power=True)\n",
    "\n",
    "spks = np.sum(output,axis=0)\n",
    "pred = np.argmax(spks)\n",
    "print(f\"Readout layer activity (spikes): {spks}\")\n",
    "print(f\"Label: {int(ds.y[i])}\")\n",
    "print(f\"Prediction: {pred}\")\n",
    "\n",
    "TSEvent.from_raster(\n",
    "            output,\n",
    "            dt=input_params[\"dt\"],\n",
    "        ).plot(marker=\"|\", s=8)\n",
    "plt.plot(0.01, ds.y[i], '>', ms=10, color='g')\n",
    "plt.plot(0.01, pred, '>', ms=10, color='r')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "times = np.arange(output.shape[0]) * input_params[\"dt\"]\n",
    "plt.plot(times, rec['Vmem_out'])\n",
    "plt.legend(range(0,7))\n",
    "plt.show()\n",
    "\n",
    "# Show active power consumption\n",
    "print(f\"Active IO power:\\t{np.mean(rec['io_power']) * 1e6}µW\\nSNN + IMU IF core:\\t{np.mean(rec['core_power']) * 1e6}µW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show idle power consumption (no evolution)\n",
    "from time import sleep\n",
    "\n",
    "mod_hdk._power_buf.clear_events()\n",
    "sleep(5.)\n",
    "power = mod_hdk._power_buf.get_events()\n",
    "\n",
    "power_idle = ([], [])\n",
    "\n",
    "for p in power:\n",
    "    power_idle[p.channel].append(p.value)\n",
    "\n",
    "idle_power_per_channel = np.mean(np.stack(power_idle), axis = 1)\n",
    "\n",
    "print(f'Idle IO power:\\t\\t{idle_power_per_channel[0] * 1e6}µW\\nSNN + IMU IF core:\\t{idle_power_per_channel[1]*1e6}µW')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynapse2rockpool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
