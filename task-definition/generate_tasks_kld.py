from commons import (
    load_data,
    filter_data_by_class,
    calc_distance_matrix,
    search_class_combinations,
)
import numpy as np
from scipy import stats
from sklearn.neighbors import KernelDensity

# OPTIONS
DATA_PATH = "../data/wisdm_watch_full_40.npz"
CLASS_LABELS_PATH = "../data/wisdm_watch_full_40_classes.json"
DEBUG = True
CLASS_KDES_CACHE_PATH = "class_kdes_cache.npy"
BUILD_KDE_CACHE = False  # Controls if the script must recalculate the KDE cache file
N_CLASSES = 2  # Controls the size of the class combinations to generate
BEST_COMBS = True  # Controls if the script must return the most separable combinations (True) or less separable ones (False).
DISPLAY_MATRIX = False  # Enables plotting the distance matrix on the screen


def calc_kde(x):
    """
    Calculates the KDE.
    Input Parameters:
      - x: Samples
    """
    kde_x = np.linspace(-20, 20, 1000)[:, np.newaxis]
    kde = KernelDensity(kernel="gaussian", bandwidth=0.5).fit(x)
    return np.exp(kde.score_samples(kde_x))


def calc_kde_class(train_x, train_y, c, n_dims):
    """
    Calculates the KDES for a single classes.
    Input Parameters:
      - train_x: Training samples
      - train_y: Training labels, must correspond with the samples
      - c: An integer selecting the class, must be in the interval 0-17
    """
    x_c = filter_data_by_class(train_x, train_y, c)
    return [calc_kde(x_c[:, :, d].flatten()[:, np.newaxis]) for d in range(n_dims)]


def calc_kde_all_classes(train_x, train_y, data_prop):
    """
    Calculates the KDEs for all the dataset classes.
    Input Parameters:
      - train_x: Training samples
      - train_y: Training labels, must correspond with the samples
      - data_prop: A dict containing properties of the data. Generated by the load_data method
    """

    if DEBUG:
        print(f"Starting KDE...")
    class_kdes = []
    for c in range(data_prop["n_classes"]):
        class_kdes.append(calc_kde_class(train_x, train_y, c, data_prop["n_dims"]))
        if DEBUG:
            print(f"Class {c} processed")
    return class_kdes


def calc_kl_divergence(p, q):
    """
    Calculates the KL divergence in both directions between the p and q KDEs.
    Input Parameters:
      - p,q: KDEs associated to the classes to compare
    """
    return stats.entropy(p, q) + stats.entropy(q, p)


def distance_fn(class_kdes, n_dims):
    """
    Initialize the distance function to employ for class combination search.
    Input Parameters:
      - class_kdes: List of the KDE for all the classes (must contain 18 elements)
      - n_dims: Number of data dimensions
    """

    def _fn(c1, c2) -> float:
        val = 0
        for d in range(n_dims):
            val += calc_kl_divergence(class_kdes[c1][d], class_kdes[c2][d])
        return val

    return _fn


if __name__ == "__main__":
    train_x, train_y, _, _, _, _, data_prop = load_data(
        DATA_PATH, CLASS_LABELS_PATH, debug=DEBUG
    )

    class_kdes = []
    if BUILD_KDE_CACHE:
        # Calculate KDE for each class
        class_kdes = calc_kde_all_classes(train_x, train_y, data_prop)
        np.save(CLASS_KDES_CACHE_PATH, class_kdes)
        if DEBUG:
            print(f"KDE cache file saved at path: {CLASS_KDES_CACHE_PATH}")
    else:
        if DEBUG:
            print(f"KDE cache file loaded from path: {CLASS_KDES_CACHE_PATH}")
        class_kdes = np.load(CLASS_KDES_CACHE_PATH)

    # Calculate KL divergence matrix
    matrix, pairs_distances_dict = calc_distance_matrix(
        distance_fn(class_kdes, data_prop["n_dims"]),
        data_prop,
        display_matrix=DISPLAY_MATRIX,
    )

    # Calculate the optimal combinations of the classes
    result_sorted = search_class_combinations(
        data_prop, pairs_distances_dict, N_CLASSES, BEST_COMBS
    )
    print(result_sorted[0:5])
