2023-10-13 18:38:00,706 - main - INFO - PyTorch is currently running on: cuda
2023-10-13 18:38:00,709 - main - INFO - Initial parameters: {'n_population': 128, 'tau_mem': 0.187, 'tau_syn': 0.08}
2023-10-13 18:38:09,022 - main - INFO - Loaded 71464 events from file ../data/wisdm_watch_full_40_encoded.npy
2023-10-13 18:38:09,214 - main - INFO - Generated events partitions: train(42878), val(14293, test(14293))
2023-10-13 18:38:09,270 - main - INFO - Built network: 
TorchSequential  with shape (12, 7) {
    LinearTorch '0_LinearTorch' with shape (12, 128)
    LIFTorch '1_LIFTorch' with shape (128, 128)
    TorchResidual '2_TorchResidual' with shape (128, 128) {
        LinearTorch '0_LinearTorch' with shape (128, 128)
        LIFTorch '1_LIFTorch' with shape (128, 128)
    }
    TorchResidual '3_TorchResidual' with shape (128, 128) {
        LinearTorch '0_LinearTorch' with shape (128, 128)
        LIFTorch '1_LIFTorch' with shape (128, 128)
    }
    LinearTorch '4_LinearTorch' with shape (128, 7)
    LIFTorch '5_LIFTorch' with shape (7, 7)
}
2023-10-13 18:38:10,188 - main - INFO - Dropped 65 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:38:10,194 - main - INFO - Dropped 65 output synapses each for 128 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:38:10,200 - main - INFO - Dropped 65 output synapses each for 128 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:38:16,442 - main - INFO - Epoch 0 -> Loss:3.2383550754407557, Acc:0.20324634436437417, Best Acc:0.20324634436437417
2023-10-13 18:39:07,644 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:39:07,650 - main - INFO - Dropped 63 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:39:07,656 - main - INFO - Dropped 63 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:40:04,816 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:40:04,822 - main - INFO - Dropped 63 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:40:04,828 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:41:02,589 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:41:02,595 - main - INFO - Dropped 63 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:41:02,601 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:41:59,803 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:41:59,809 - main - INFO - Dropped 63 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:41:59,815 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:42:56,742 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:42:56,748 - main - INFO - Dropped 63 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:42:56,754 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:43:53,782 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:43:53,788 - main - INFO - Dropped 63 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:43:53,794 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:44:50,706 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:44:50,712 - main - INFO - Dropped 63 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:44:50,718 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:45:47,598 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:45:47,604 - main - INFO - Dropped 63 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:45:47,610 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:46:45,149 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:46:45,155 - main - INFO - Dropped 63 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:46:45,161 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:47:42,095 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:47:42,101 - main - INFO - Dropped 63 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:47:42,107 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:47:47,835 - main - INFO - Epoch 100 -> Loss:0.8502864517816683, Acc:0.7004827537955642, Best Acc:0.7231511928916252
2023-10-13 18:48:38,984 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:48:38,990 - main - INFO - Dropped 63 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:48:38,996 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:49:36,069 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:49:36,074 - main - INFO - Dropped 64 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:49:36,080 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:50:33,002 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:50:33,008 - main - INFO - Dropped 64 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:50:33,014 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:51:29,803 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:51:29,809 - main - INFO - Dropped 64 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:51:29,815 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:52:26,649 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:52:26,655 - main - INFO - Dropped 64 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:52:26,661 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:53:23,528 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:53:23,534 - main - INFO - Dropped 64 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:53:23,540 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:54:20,406 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:54:20,412 - main - INFO - Dropped 64 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:54:20,418 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:55:17,181 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:55:17,187 - main - INFO - Dropped 64 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:55:17,193 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:56:13,975 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:56:13,981 - main - INFO - Dropped 64 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:56:13,987 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:57:11,353 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:57:11,359 - main - INFO - Dropped 64 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:57:11,365 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:57:17,349 - main - INFO - Epoch 200 -> Loss:0.6342158070424708, Acc:0.7659693556286293, Best Acc:0.7760442174491009
2023-10-13 18:58:21,118 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:58:21,124 - main - INFO - Dropped 64 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:58:21,130 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:59:18,335 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 18:59:18,341 - main - INFO - Dropped 64 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 18:59:18,347 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 19:00:19,176 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 19:00:19,182 - main - INFO - Dropped 64 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 19:00:19,188 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 19:01:15,698 - main - INFO - Dropped 61 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-13 19:01:15,704 - main - INFO - Dropped 64 output synapses each for 122 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 19:01:15,710 - main - INFO - Dropped 64 output synapses each for 127 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-13 19:02:12,279 - main - INFO - Training finished with accuracy: 0.7826908276778842
