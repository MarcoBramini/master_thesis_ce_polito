2023-10-20 01:15:22,329 - main - INFO - PyTorch is currently running on: cuda
2023-10-20 01:15:22,333 - main - INFO - Initial parameters: {'n_population': 128, 'tau_mem': 0.153, 'tau_syn': 0.082}
2023-10-20 01:15:30,435 - main - INFO - Loaded 71464 events from file ../data/wisdm_watch_full_40_encoded.npy
2023-10-20 01:15:30,583 - main - INFO - Generated events partitions: train(42878), val(14293, test(14293))
2023-10-20 01:15:30,637 - main - INFO - Built network: 
TorchSequential  with shape (12, 7) {
    LinearTorch '0_LinearTorch' with shape (12, 128)
    LIFTorch '1_LIFTorch' with shape (128, 128)
    TorchResidual '2_TorchResidual' with shape (128, 128) {
        LinearTorch '0_LinearTorch' with shape (128, 128)
        LIFTorch '1_LIFTorch' with shape (128, 128)
    }
    LinearTorch '3_LinearTorch' with shape (128, 7)
    LIFTorch '4_LIFTorch' with shape (7, 7)
}
2023-10-20 01:15:32,148 - main - INFO - Dropped 65 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:15:32,154 - main - INFO - Dropped 65 output synapses each for 128 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:15:39,296 - main - INFO - Epoch 0 -> Loss:8.99362305024775, Acc:0.17805918981319527, Best Acc:0.17805918981319527
2023-10-20 01:16:34,290 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:16:34,296 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:17:35,529 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:17:35,535 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:18:36,708 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:18:36,714 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:19:38,041 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:19:38,047 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:20:39,338 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:20:39,344 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:21:40,499 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:21:40,505 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:22:41,694 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:22:41,700 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:23:43,017 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:23:43,023 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:24:44,247 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:24:44,254 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:25:45,258 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:25:45,264 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:25:51,388 - main - INFO - Epoch 100 -> Loss:0.7776827826732542, Acc:0.7179038690267963, Best Acc:0.7371440565311691
2023-10-20 01:26:46,405 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:26:46,411 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:27:47,664 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:27:47,670 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:28:48,833 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:28:48,839 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:29:49,933 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:29:49,939 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:30:51,076 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:30:51,082 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:31:52,297 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:31:52,303 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:32:53,573 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:32:53,579 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:33:54,768 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:33:54,774 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:34:49,522 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:34:49,528 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:35:47,514 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:35:47,521 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:35:53,182 - main - INFO - Epoch 200 -> Loss:0.6492842566676256, Acc:0.7462394178968725, Best Acc:0.7639403904008955
2023-10-20 01:36:45,250 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:36:45,256 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:37:43,017 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:37:43,023 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:38:40,296 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:38:40,303 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:39:39,388 - main - INFO - Dropped 62 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-20 01:39:39,394 - main - INFO - Dropped 64 output synapses each for 123 neurons in layer LinearTorch '0_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-20 01:40:37,531 - main - INFO - Training finished with accuracy: 0.7732456447211922
