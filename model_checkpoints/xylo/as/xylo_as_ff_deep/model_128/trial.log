2023-10-18 11:39:47,926 - main - INFO - PyTorch is currently running on: cuda
2023-10-18 11:39:47,930 - main - INFO - Initial parameters: {'n_population': 128, 'tau_mem': 0.068, 'tau_syn': 0.127}
2023-10-18 11:39:55,949 - main - INFO - Loaded 71464 events from file ../data/4bit_spikeset_PHASE_full.npy
2023-10-18 11:39:56,097 - main - INFO - Generated events partitions: train(42878), val(14293, test(14293))
2023-10-18 11:39:56,148 - main - INFO - Built network: 
TorchSequential  with shape (12, 7) {
    LinearTorch '0_LinearTorch' with shape (12, 128)
    LIFTorch '1_LIFTorch' with shape (128, 128)
    LinearTorch '2_LinearTorch' with shape (128, 128)
    LIFTorch '3_LIFTorch' with shape (128, 128)
    LinearTorch '4_LinearTorch' with shape (128, 7)
    LIFTorch '5_LIFTorch' with shape (7, 7)
}
2023-10-18 11:39:57,490 - main - INFO - Dropped 65 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 11:39:57,496 - main - INFO - Dropped 65 output synapses each for 128 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 11:40:04,628 - main - INFO - Epoch 0 -> Loss:4.210222971148607, Acc:0.16749457776533966, Best Acc:0.16749457776533966
2023-10-18 11:40:59,720 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 11:40:59,726 - main - INFO - Dropped 64 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 11:42:01,048 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 11:42:01,054 - main - INFO - Dropped 64 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 11:43:02,479 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 11:43:02,485 - main - INFO - Dropped 64 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 11:44:03,969 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 11:44:03,975 - main - INFO - Dropped 65 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 11:45:05,263 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 11:45:05,269 - main - INFO - Dropped 65 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 11:46:06,401 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 11:46:06,407 - main - INFO - Dropped 65 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 11:47:07,729 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 11:47:07,734 - main - INFO - Dropped 65 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 11:48:08,933 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 11:48:08,938 - main - INFO - Dropped 65 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 11:49:10,152 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 11:49:10,157 - main - INFO - Dropped 65 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 11:50:11,319 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 11:50:11,328 - main - INFO - Dropped 65 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 11:50:17,528 - main - INFO - Epoch 100 -> Loss:0.9997088545706214, Acc:0.7129364024347582, Best Acc:0.7129364024347582
2023-10-18 11:51:12,633 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 11:51:12,639 - main - INFO - Dropped 65 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 11:52:13,877 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 11:52:13,883 - main - INFO - Dropped 65 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 11:53:15,107 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 11:53:15,113 - main - INFO - Dropped 65 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 11:54:16,243 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 11:54:16,249 - main - INFO - Dropped 65 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 11:55:17,467 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 11:55:17,473 - main - INFO - Dropped 65 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 11:56:18,862 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 11:56:18,868 - main - INFO - Dropped 65 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 11:57:20,236 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 11:57:20,242 - main - INFO - Dropped 65 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 11:58:21,495 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 11:58:21,501 - main - INFO - Dropped 65 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 11:59:22,732 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 11:59:22,738 - main - INFO - Dropped 65 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 12:00:23,983 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 12:00:23,988 - main - INFO - Dropped 65 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 12:00:30,202 - main - INFO - Epoch 200 -> Loss:0.7086182614652122, Acc:0.7386832715315189, Best Acc:0.7562443153991464
2023-10-18 12:01:25,401 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 12:01:25,407 - main - INFO - Dropped 65 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 12:02:26,703 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 12:02:26,709 - main - INFO - Dropped 65 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 12:03:18,063 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 12:03:18,069 - main - INFO - Dropped 65 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 12:04:11,612 - main - INFO - Dropped 60 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 128) (Rec:None)
2023-10-18 12:04:11,617 - main - INFO - Dropped 65 output synapses each for 122 neurons in layer LinearTorch '2_LinearTorch' with shape (128, 128) (Rec:None)
2023-10-18 12:05:05,278 - main - INFO - Training finished with accuracy: 0.7630308542643252
