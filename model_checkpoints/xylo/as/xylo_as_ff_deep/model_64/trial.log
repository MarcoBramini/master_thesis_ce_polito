2023-10-18 21:56:36,547 - main - INFO - PyTorch is currently running on: cuda
2023-10-18 21:56:36,551 - main - INFO - Initial parameters: {'n_population': 64, 'tau_mem': 0.06, 'tau_syn': 0.093}
2023-10-18 21:56:44,518 - main - INFO - Loaded 71464 events from file ../data/wisdm_watch_full_40_encoded.npy
2023-10-18 21:56:44,665 - main - INFO - Generated events partitions: train(42878), val(14293, test(14293))
2023-10-18 21:56:44,717 - main - INFO - Built network: 
TorchSequential  with shape (12, 7) {
    LinearTorch '0_LinearTorch' with shape (12, 64)
    LIFTorch '1_LIFTorch' with shape (64, 64)
    LinearTorch '2_LinearTorch' with shape (64, 64)
    LIFTorch '3_LIFTorch' with shape (64, 64)
    LinearTorch '4_LinearTorch' with shape (64, 7)
    LIFTorch '5_LIFTorch' with shape (7, 7)
}
2023-10-18 21:56:46,059 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 21:56:46,062 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 21:56:51,409 - main - INFO - Epoch 0 -> Loss:2.2162952219567646, Acc:0.23633946687189533, Best Acc:0.23633946687189533
2023-10-18 21:57:29,963 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 21:57:29,969 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 21:58:12,871 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 21:58:12,873 - main - INFO - Dropped 1 output synapses each for 63 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 21:58:55,948 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 21:58:55,951 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 21:59:38,864 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 21:59:38,867 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 22:00:21,753 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 22:00:21,756 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 22:01:04,820 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 22:01:04,823 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 22:01:47,679 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 22:01:47,682 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 22:02:30,539 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 22:02:30,542 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 22:03:13,353 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 22:03:13,356 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 22:03:56,133 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 22:03:56,136 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 22:04:00,501 - main - INFO - Epoch 100 -> Loss:0.8397945412775365, Acc:0.7167844399356328, Best Acc:0.7232211572098229
2023-10-18 22:04:39,093 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 22:04:39,096 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 22:05:21,836 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 22:05:21,839 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 22:06:04,808 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 22:06:04,811 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 22:06:47,756 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 22:06:47,759 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 22:07:30,754 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 22:07:30,757 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 22:08:13,770 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 22:08:13,773 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 22:08:56,757 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 22:08:56,760 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 22:09:39,740 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 22:09:39,743 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 22:10:22,827 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 22:10:22,830 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 22:11:05,509 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 22:11:05,512 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 22:11:09,886 - main - INFO - Epoch 200 -> Loss:0.7430950752118739, Acc:0.7379836283495417, Best Acc:0.7402924508500665
2023-10-18 22:11:45,280 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 22:11:45,283 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 22:12:27,743 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 22:12:27,746 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 22:13:10,733 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 22:13:10,736 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 22:13:53,671 - main - INFO - Dropped 1 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 64) (Rec:None)
2023-10-18 22:13:53,674 - main - INFO - Dropped 1 output synapses each for 64 neurons in layer LinearTorch '2_LinearTorch' with shape (64, 64) (Rec:None)
2023-10-18 22:14:36,624 - main - INFO - Training finished with accuracy: 0.7483383474428041
