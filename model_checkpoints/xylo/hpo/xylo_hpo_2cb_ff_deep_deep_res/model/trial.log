2023-10-28 13:38:08,851 - main - INFO - PyTorch is currently running on: cuda
2023-10-28 13:38:08,855 - main - INFO - Initial parameters: {'n_population': 256, 'tau_mem': 0.081, 'tau_syn': 0.077}
2023-10-28 13:38:11,596 - main - INFO - Loaded 20697 events from file ../data/wisdm_watch_full_40_encoded.npy
2023-10-28 13:38:11,646 - main - INFO - Generated events partitions: train(12418), val(4139, test(4140))
2023-10-28 13:38:11,681 - main - INFO - Built network: 
TorchSequential  with shape (12, 2) {
    LinearTorch '0_LinearTorch' with shape (12, 256)
    LIFTorch '1_LIFTorch' with shape (256, 256)
    TorchResidual '2_TorchResidual' with shape (256, 256) {
        LinearTorch '0_LinearTorch' with shape (256, 256)
        LIFTorch '1_LIFTorch' with shape (256, 256)
    }
    TorchResidual '3_TorchResidual' with shape (256, 256) {
        LinearTorch '0_LinearTorch' with shape (256, 256)
        LIFTorch '1_LIFTorch' with shape (256, 256)
    }
    LinearTorch '4_LinearTorch' with shape (256, 2)
    LIFTorch '5_LIFTorch' with shape (2, 2)
}
2023-10-28 13:38:13,167 - main - INFO - Dropped 193 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:38:13,183 - main - INFO - Dropped 193 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:38:13,199 - main - INFO - Dropped 193 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:38:18,586 - main - INFO - Epoch 0 -> Loss:0.6054089864095052, Acc:0.5155834742691471, Best Acc:0.5155834742691471
2023-10-28 13:38:56,215 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:38:56,227 - main - INFO - Dropped 168 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:38:56,241 - main - INFO - Dropped 181 output synapses each for 249 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:39:38,277 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:39:38,288 - main - INFO - Dropped 174 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:39:38,302 - main - INFO - Dropped 185 output synapses each for 251 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:40:20,650 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:40:20,664 - main - INFO - Dropped 177 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:40:20,680 - main - INFO - Dropped 186 output synapses each for 252 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:41:02,666 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:41:02,678 - main - INFO - Dropped 177 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:41:02,693 - main - INFO - Dropped 188 output synapses each for 252 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:41:44,475 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:41:44,489 - main - INFO - Dropped 178 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:41:44,505 - main - INFO - Dropped 188 output synapses each for 252 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:42:26,302 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:42:26,314 - main - INFO - Dropped 179 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:42:26,328 - main - INFO - Dropped 188 output synapses each for 252 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:43:08,367 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:43:08,383 - main - INFO - Dropped 179 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:43:08,399 - main - INFO - Dropped 188 output synapses each for 252 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:43:50,177 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:43:50,189 - main - INFO - Dropped 180 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:43:50,203 - main - INFO - Dropped 189 output synapses each for 252 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:44:32,228 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:44:32,240 - main - INFO - Dropped 180 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:44:32,254 - main - INFO - Dropped 189 output synapses each for 252 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:45:14,225 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:45:14,237 - main - INFO - Dropped 180 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:45:14,251 - main - INFO - Dropped 189 output synapses each for 252 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:45:18,470 - main - INFO - Epoch 100 -> Loss:0.047007859063645206, Acc:0.9876781831360232, Best Acc:0.9903358299106064
2023-10-28 13:45:50,977 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:45:50,989 - main - INFO - Dropped 180 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:45:51,004 - main - INFO - Dropped 189 output synapses each for 252 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:46:33,021 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:46:33,033 - main - INFO - Dropped 180 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:46:33,047 - main - INFO - Dropped 189 output synapses each for 252 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:47:14,913 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:47:14,925 - main - INFO - Dropped 180 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:47:14,940 - main - INFO - Dropped 189 output synapses each for 252 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:47:56,772 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:47:56,784 - main - INFO - Dropped 180 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:47:56,798 - main - INFO - Dropped 189 output synapses each for 252 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:48:38,624 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:48:38,637 - main - INFO - Dropped 180 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:48:38,651 - main - INFO - Dropped 189 output synapses each for 252 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:49:20,669 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:49:20,681 - main - INFO - Dropped 181 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:49:20,695 - main - INFO - Dropped 189 output synapses each for 252 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:50:02,712 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:50:02,726 - main - INFO - Dropped 181 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:50:02,740 - main - INFO - Dropped 190 output synapses each for 252 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:50:44,782 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:50:44,794 - main - INFO - Dropped 181 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:50:44,809 - main - INFO - Dropped 189 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:51:26,690 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:51:26,704 - main - INFO - Dropped 181 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:51:26,720 - main - INFO - Dropped 189 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:52:08,830 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:52:08,842 - main - INFO - Dropped 181 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:52:08,857 - main - INFO - Dropped 190 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:52:13,123 - main - INFO - Epoch 200 -> Loss:0.028857965332766373, Acc:0.9869533703793186, Best Acc:0.99251026818072
2023-10-28 13:52:45,176 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:52:45,188 - main - INFO - Dropped 181 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:52:45,202 - main - INFO - Dropped 190 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:53:27,108 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:53:27,125 - main - INFO - Dropped 182 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:53:27,141 - main - INFO - Dropped 190 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:54:08,886 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:54:08,898 - main - INFO - Dropped 182 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:54:08,913 - main - INFO - Dropped 190 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:54:50,658 - main - INFO - Dropped 151 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 13:54:50,672 - main - INFO - Dropped 182 output synapses each for 207 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:54:50,687 - main - INFO - Dropped 190 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 13:55:32,516 - main - INFO - Training finished with accuracy: 0.993959893694129
