2023-11-02 02:03:26,799 - main - INFO - PyTorch is currently running on: cuda
2023-11-02 02:03:26,803 - main - INFO - Initial parameters: {'n_population': 256, 'tau_mem': 0.08700000000000001, 'tau_syn': 0.082}
2023-11-02 02:03:30,611 - main - INFO - Loaded 30749 events from file ../data/wisdm_watch_full_40_encoded.npy
2023-11-02 02:03:30,677 - main - INFO - Generated events partitions: train(18449), val(6150, test(6150))
2023-11-02 02:03:30,712 - main - INFO - Built network: 
TorchSequential  with shape (12, 3) {
    LinearTorch '0_LinearTorch' with shape (12, 256)
    LIFTorch '1_LIFTorch' with shape (256, 256)
    TorchResidual '2_TorchResidual' with shape (256, 256) {
        LinearTorch '0_LinearTorch' with shape (256, 256)
        LIFTorch '1_LIFTorch' with shape (256, 256)
    }
    TorchResidual '3_TorchResidual' with shape (256, 256) {
        LinearTorch '0_LinearTorch' with shape (256, 256)
        LIFTorch '1_LIFTorch' with shape (256, 256)
    }
    LinearTorch '4_LinearTorch' with shape (256, 3)
    LIFTorch '5_LIFTorch' with shape (3, 3)
}
2023-11-02 02:03:32,022 - main - INFO - Dropped 193 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:03:32,038 - main - INFO - Dropped 193 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:03:32,053 - main - INFO - Dropped 193 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:03:39,379 - main - INFO - Epoch 0 -> Loss:1.099489493502511, Acc:0.5852032520325203, Best Acc:0.5852032520325203
2023-11-02 02:04:35,421 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:04:35,433 - main - INFO - Dropped 181 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:04:35,447 - main - INFO - Dropped 185 output synapses each for 249 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:05:37,863 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:05:37,875 - main - INFO - Dropped 186 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:05:37,891 - main - INFO - Dropped 189 output synapses each for 252 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:06:40,325 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:06:40,338 - main - INFO - Dropped 187 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:06:40,354 - main - INFO - Dropped 190 output synapses each for 252 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:07:42,235 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:07:42,249 - main - INFO - Dropped 188 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:07:42,265 - main - INFO - Dropped 190 output synapses each for 253 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:08:44,643 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:08:44,655 - main - INFO - Dropped 189 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:08:44,670 - main - INFO - Dropped 190 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:09:46,948 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:09:46,960 - main - INFO - Dropped 189 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:09:46,976 - main - INFO - Dropped 191 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:10:49,149 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:10:49,160 - main - INFO - Dropped 189 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:10:49,175 - main - INFO - Dropped 191 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:11:51,562 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:11:51,576 - main - INFO - Dropped 189 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:11:51,592 - main - INFO - Dropped 191 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:12:53,833 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:12:53,844 - main - INFO - Dropped 189 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:12:53,859 - main - INFO - Dropped 191 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:13:56,423 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:13:56,436 - main - INFO - Dropped 190 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:13:56,453 - main - INFO - Dropped 191 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:14:02,737 - main - INFO - Epoch 100 -> Loss:0.30335599349604714, Acc:0.8998373983739837, Best Acc:0.9102439024390244
2023-11-02 02:14:58,775 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:14:58,787 - main - INFO - Dropped 190 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:14:58,801 - main - INFO - Dropped 191 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:16:01,635 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:16:01,646 - main - INFO - Dropped 190 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:16:01,661 - main - INFO - Dropped 191 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:17:03,773 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:17:03,786 - main - INFO - Dropped 190 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:17:03,803 - main - INFO - Dropped 191 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:18:06,283 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:18:06,296 - main - INFO - Dropped 190 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:18:06,312 - main - INFO - Dropped 191 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:19:08,558 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:19:08,571 - main - INFO - Dropped 190 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:19:08,587 - main - INFO - Dropped 191 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:20:10,981 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:20:10,993 - main - INFO - Dropped 190 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:20:11,007 - main - INFO - Dropped 192 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:21:13,283 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:21:13,295 - main - INFO - Dropped 190 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:21:13,311 - main - INFO - Dropped 192 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:22:15,502 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:22:15,514 - main - INFO - Dropped 190 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:22:15,528 - main - INFO - Dropped 192 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:23:18,088 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:23:18,100 - main - INFO - Dropped 190 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:23:18,114 - main - INFO - Dropped 192 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:24:14,697 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:24:14,709 - main - INFO - Dropped 190 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:24:14,723 - main - INFO - Dropped 192 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:24:21,007 - main - INFO - Epoch 200 -> Loss:0.21346598780817455, Acc:0.9102439024390244, Best Acc:0.9188617886178861
2023-11-02 02:25:16,857 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:25:16,869 - main - INFO - Dropped 190 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:25:16,883 - main - INFO - Dropped 192 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:26:19,077 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:26:19,089 - main - INFO - Dropped 190 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:26:19,104 - main - INFO - Dropped 192 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:27:21,185 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:27:21,197 - main - INFO - Dropped 190 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:27:21,212 - main - INFO - Dropped 192 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:28:23,449 - main - INFO - Dropped 141 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-02 02:28:23,461 - main - INFO - Dropped 190 output synapses each for 196 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:28:23,475 - main - INFO - Dropped 192 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-02 02:29:25,662 - main - INFO - Training finished with accuracy: 0.9217886178861788
