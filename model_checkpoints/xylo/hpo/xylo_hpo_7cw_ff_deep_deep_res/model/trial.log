2023-11-09 02:08:56,242 - main - INFO - PyTorch is currently running on: cuda
2023-11-09 02:08:56,246 - main - INFO - Initial parameters: {'n_population': 256, 'tau_mem': 0.134, 'tau_syn': 0.109}
2023-11-09 02:09:04,247 - main - INFO - Loaded 71947 events from file ../data/4bit_spikeset_PHASE_full.npy
2023-11-09 02:09:04,390 - main - INFO - Generated events partitions: train(43168), val(14389, test(14390))
2023-11-09 02:09:04,445 - main - INFO - Built network: 
TorchSequential  with shape (12, 7) {
    LinearTorch '0_LinearTorch' with shape (12, 256)
    LIFTorch '1_LIFTorch' with shape (256, 256)
    TorchResidual '2_TorchResidual' with shape (256, 256) {
        LinearTorch '0_LinearTorch' with shape (256, 256)
        LIFTorch '1_LIFTorch' with shape (256, 256)
    }
    TorchResidual '3_TorchResidual' with shape (256, 256) {
        LinearTorch '0_LinearTorch' with shape (256, 256)
        LIFTorch '1_LIFTorch' with shape (256, 256)
    }
    LinearTorch '4_LinearTorch' with shape (256, 7)
    LIFTorch '5_LIFTorch' with shape (7, 7)
}
2023-11-09 02:09:05,863 - main - INFO - Dropped 193 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-09 02:09:05,878 - main - INFO - Dropped 193 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-09 02:09:05,892 - main - INFO - Dropped 193 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-09 02:09:21,602 - main - INFO - Epoch 0 -> Loss:4.321657966999781, Acc:0.14385989297379942, Best Acc:0.14385989297379942
2023-11-09 02:11:32,689 - main - INFO - Dropped 144 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-09 02:11:32,702 - main - INFO - Dropped 188 output synapses each for 198 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-09 02:11:32,718 - main - INFO - Dropped 190 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-09 02:13:59,295 - main - INFO - Dropped 144 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-09 02:13:59,307 - main - INFO - Dropped 189 output synapses each for 198 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-09 02:13:59,321 - main - INFO - Dropped 191 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-09 02:16:25,144 - main - INFO - Dropped 144 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-09 02:16:25,156 - main - INFO - Dropped 190 output synapses each for 198 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-09 02:16:25,170 - main - INFO - Dropped 191 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-09 02:18:50,957 - main - INFO - Dropped 144 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-09 02:18:50,970 - main - INFO - Dropped 190 output synapses each for 198 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-09 02:18:50,986 - main - INFO - Dropped 191 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-09 02:21:16,939 - main - INFO - Dropped 144 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-09 02:21:16,950 - main - INFO - Dropped 190 output synapses each for 198 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-09 02:21:16,964 - main - INFO - Dropped 191 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-09 02:23:42,781 - main - INFO - Dropped 144 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-09 02:23:42,794 - main - INFO - Dropped 190 output synapses each for 198 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-09 02:23:42,810 - main - INFO - Dropped 191 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-09 02:26:08,694 - main - INFO - Dropped 144 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-09 02:26:08,713 - main - INFO - Dropped 190 output synapses each for 198 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-09 02:26:08,729 - main - INFO - Dropped 191 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-09 02:28:34,671 - main - INFO - Dropped 144 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-09 02:28:34,683 - main - INFO - Dropped 190 output synapses each for 198 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-09 02:28:34,697 - main - INFO - Dropped 191 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-09 02:31:00,737 - main - INFO - Dropped 144 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-09 02:31:00,748 - main - INFO - Dropped 190 output synapses each for 198 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-09 02:31:00,763 - main - INFO - Dropped 191 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-09 02:33:26,729 - main - INFO - Dropped 144 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 12:51:39,728 - main - INFO - PyTorch is currently running on: cuda
2023-11-12 12:51:39,732 - main - INFO - Initial parameters: {'n_population': 256, 'tau_mem': 0.191, 'tau_syn': 0.076}
2023-11-12 12:51:47,783 - main - INFO - Loaded 71947 events from file ../data/4bit_spikeset_PHASE_full.npy
2023-11-12 12:51:47,928 - main - INFO - Generated events partitions: train(43168), val(14389, test(14390))
2023-11-12 12:51:47,981 - main - INFO - Built network: 
TorchSequential  with shape (12, 7) {
    LinearTorch '0_LinearTorch' with shape (12, 256)
    LIFTorch '1_LIFTorch' with shape (256, 256)
    TorchResidual '2_TorchResidual' with shape (256, 256) {
        LinearTorch '0_LinearTorch' with shape (256, 256)
        LIFTorch '1_LIFTorch' with shape (256, 256)
    }
    TorchResidual '3_TorchResidual' with shape (256, 256) {
        LinearTorch '0_LinearTorch' with shape (256, 256)
        LIFTorch '1_LIFTorch' with shape (256, 256)
    }
    LinearTorch '4_LinearTorch' with shape (256, 7)
    LIFTorch '5_LIFTorch' with shape (7, 7)
}
2023-11-12 12:51:49,304 - main - INFO - Dropped 193 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 12:51:49,320 - main - INFO - Dropped 193 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 12:51:49,336 - main - INFO - Dropped 193 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 12:52:04,966 - main - INFO - Epoch 0 -> Loss:2.3623071369670687, Acc:0.15352005003822364, Best Acc:0.15352005003822364
2023-11-12 12:54:15,839 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 12:54:15,859 - main - INFO - Dropped 185 output synapses each for 205 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 12:54:15,875 - main - INFO - Dropped 184 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 12:56:40,761 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 12:56:40,781 - main - INFO - Dropped 187 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 12:56:40,805 - main - INFO - Dropped 187 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 12:59:05,250 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 12:59:05,263 - main - INFO - Dropped 188 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 12:59:05,279 - main - INFO - Dropped 187 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:01:29,988 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 13:01:29,999 - main - INFO - Dropped 189 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:01:30,015 - main - INFO - Dropped 188 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:03:55,245 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 13:03:55,259 - main - INFO - Dropped 189 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:03:55,275 - main - INFO - Dropped 189 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:06:19,496 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 13:06:19,508 - main - INFO - Dropped 189 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:06:19,522 - main - INFO - Dropped 190 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:08:44,216 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 13:08:44,228 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:08:44,243 - main - INFO - Dropped 190 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:10:59,589 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 13:10:59,601 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:10:59,617 - main - INFO - Dropped 190 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:13:24,135 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 13:13:24,149 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:13:24,165 - main - INFO - Dropped 190 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:15:48,738 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 13:15:48,752 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:15:48,768 - main - INFO - Dropped 190 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:16:03,359 - main - INFO - Epoch 100 -> Loss:1.2345037829308283, Acc:0.5386753770241156, Best Acc:0.5505594551393426
2023-11-12 13:18:13,392 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 13:18:13,404 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:18:13,418 - main - INFO - Dropped 190 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:20:38,245 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 13:20:38,257 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:20:38,271 - main - INFO - Dropped 190 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:23:03,199 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 13:23:03,211 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:23:03,225 - main - INFO - Dropped 190 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:25:27,807 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 13:25:27,819 - main - INFO - Dropped 190 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:25:27,833 - main - INFO - Dropped 190 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:27:52,232 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 13:27:52,244 - main - INFO - Dropped 191 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:27:52,258 - main - INFO - Dropped 190 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:30:16,521 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 13:30:16,533 - main - INFO - Dropped 191 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:30:16,547 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:32:41,269 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 13:32:41,281 - main - INFO - Dropped 191 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:32:41,295 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:35:06,036 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 13:35:06,050 - main - INFO - Dropped 191 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:35:06,066 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:37:31,058 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 13:37:31,070 - main - INFO - Dropped 191 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:37:31,085 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:39:55,308 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 13:39:55,320 - main - INFO - Dropped 191 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:39:55,335 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:40:09,956 - main - INFO - Epoch 200 -> Loss:1.1170757412910461, Acc:0.5407603030092432, Best Acc:0.5786364584057266
2023-11-12 13:42:19,682 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 13:42:19,694 - main - INFO - Dropped 191 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:42:19,708 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:44:44,467 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 13:44:44,480 - main - INFO - Dropped 191 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:44:44,494 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:47:09,198 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 13:47:09,210 - main - INFO - Dropped 191 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:47:09,225 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:49:34,164 - main - INFO - Dropped 149 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-12 13:49:34,176 - main - INFO - Dropped 191 output synapses each for 206 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:49:34,190 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-12 13:51:58,833 - main - INFO - Training finished with accuracy: 0.583084300507332
