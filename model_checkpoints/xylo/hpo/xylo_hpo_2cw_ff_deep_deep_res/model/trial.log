2023-10-28 14:37:36,758 - main - INFO - PyTorch is currently running on: cuda
2023-10-28 14:37:36,762 - main - INFO - Initial parameters: {'n_population': 256, 'tau_mem': 0.049, 'tau_syn': 0.10200000000000001}
2023-10-28 14:37:39,415 - main - INFO - Loaded 19798 events from file ../data/wisdm_watch_full_40_encoded.npy
2023-10-28 14:37:39,463 - main - INFO - Generated events partitions: train(11878), val(3960, test(3960))
2023-10-28 14:37:39,497 - main - INFO - Built network: 
TorchSequential  with shape (12, 2) {
    LinearTorch '0_LinearTorch' with shape (12, 256)
    LIFTorch '1_LIFTorch' with shape (256, 256)
    TorchResidual '2_TorchResidual' with shape (256, 256) {
        LinearTorch '0_LinearTorch' with shape (256, 256)
        LIFTorch '1_LIFTorch' with shape (256, 256)
    }
    TorchResidual '3_TorchResidual' with shape (256, 256) {
        LinearTorch '0_LinearTorch' with shape (256, 256)
        LIFTorch '1_LIFTorch' with shape (256, 256)
    }
    LinearTorch '4_LinearTorch' with shape (256, 2)
    LIFTorch '5_LIFTorch' with shape (2, 2)
}
2023-10-28 14:37:40,981 - main - INFO - Dropped 193 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:37:40,995 - main - INFO - Dropped 193 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:37:41,009 - main - INFO - Dropped 193 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:37:46,063 - main - INFO - Epoch 0 -> Loss:0.8042914162982594, Acc:0.527020202020202, Best Acc:0.527020202020202
2023-10-28 14:38:21,033 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:38:21,046 - main - INFO - Dropped 180 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:38:21,061 - main - INFO - Dropped 183 output synapses each for 253 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:38:59,712 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:38:59,725 - main - INFO - Dropped 186 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:38:59,741 - main - INFO - Dropped 188 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:39:38,271 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:39:38,285 - main - INFO - Dropped 187 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:39:38,301 - main - INFO - Dropped 189 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:40:16,809 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:40:16,820 - main - INFO - Dropped 187 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:40:16,834 - main - INFO - Dropped 190 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:40:55,599 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:40:55,610 - main - INFO - Dropped 188 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:40:55,625 - main - INFO - Dropped 191 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:41:34,153 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:41:34,165 - main - INFO - Dropped 188 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:41:34,179 - main - INFO - Dropped 191 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:42:12,474 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:42:12,489 - main - INFO - Dropped 188 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:42:12,505 - main - INFO - Dropped 192 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:42:51,092 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:42:51,103 - main - INFO - Dropped 188 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:42:51,118 - main - INFO - Dropped 192 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:43:29,669 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:43:29,680 - main - INFO - Dropped 188 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:43:29,695 - main - INFO - Dropped 192 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:44:08,240 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:44:08,251 - main - INFO - Dropped 189 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:44:08,266 - main - INFO - Dropped 192 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:44:12,131 - main - INFO - Epoch 100 -> Loss:0.4639458493752913, Acc:0.7724747474747474, Best Acc:0.7883838383838384
2023-10-28 14:44:46,647 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:44:46,658 - main - INFO - Dropped 189 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:44:46,673 - main - INFO - Dropped 192 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:45:25,302 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:45:25,315 - main - INFO - Dropped 189 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:45:25,331 - main - INFO - Dropped 192 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:46:03,956 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:46:03,968 - main - INFO - Dropped 190 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:46:03,982 - main - INFO - Dropped 192 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:46:42,443 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:46:42,454 - main - INFO - Dropped 190 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:46:42,471 - main - INFO - Dropped 192 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:47:21,015 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:47:21,027 - main - INFO - Dropped 190 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:47:21,041 - main - INFO - Dropped 192 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:47:58,549 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:47:58,565 - main - INFO - Dropped 190 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:47:58,626 - main - INFO - Dropped 192 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:48:32,273 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:48:32,285 - main - INFO - Dropped 190 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:48:32,299 - main - INFO - Dropped 192 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:49:10,714 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:49:10,725 - main - INFO - Dropped 190 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:49:10,739 - main - INFO - Dropped 192 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:49:49,148 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:49:49,160 - main - INFO - Dropped 190 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:49:49,174 - main - INFO - Dropped 192 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:50:27,741 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:50:27,754 - main - INFO - Dropped 190 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:50:27,770 - main - INFO - Dropped 192 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:50:31,633 - main - INFO - Epoch 200 -> Loss:0.3426502292806452, Acc:0.7696969696969697, Best Acc:0.8184343434343434
2023-10-28 14:51:06,089 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:51:06,101 - main - INFO - Dropped 190 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:51:06,115 - main - INFO - Dropped 192 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:51:44,589 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:51:44,600 - main - INFO - Dropped 191 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:51:44,615 - main - INFO - Dropped 192 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:52:23,130 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:52:23,141 - main - INFO - Dropped 191 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:52:23,156 - main - INFO - Dropped 192 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:53:01,859 - main - INFO - Dropped 142 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-10-28 14:53:01,878 - main - INFO - Dropped 191 output synapses each for 197 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:53:01,897 - main - INFO - Dropped 192 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-10-28 14:53:40,539 - main - INFO - Training finished with accuracy: 0.8282828282828283
