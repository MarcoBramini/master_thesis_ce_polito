2023-11-06 17:41:57,957 - main - INFO - PyTorch is currently running on: cuda
2023-11-06 17:41:57,961 - main - INFO - Initial parameters: {'n_population': 256, 'tau_mem': 0.193, 'tau_syn': 0.08}
2023-11-06 17:42:02,840 - main - INFO - Loaded 40938 events from file ../data/wisdm_watch_full_40_encoded.npy
2023-11-06 17:42:02,931 - main - INFO - Generated events partitions: train(24562), val(8188, test(8188))
2023-11-06 17:42:02,973 - main - INFO - Built network: 
TorchSequential  with shape (12, 4) {
    LinearTorch '0_LinearTorch' with shape (12, 256)
    LIFTorch '1_LIFTorch' with shape (256, 256)
    TorchResidual '2_TorchResidual' with shape (256, 256) {
        LinearTorch '0_LinearTorch' with shape (256, 256)
        LIFTorch '1_LIFTorch' with shape (256, 256)
    }
    TorchResidual '3_TorchResidual' with shape (256, 256) {
        LinearTorch '0_LinearTorch' with shape (256, 256)
        LIFTorch '1_LIFTorch' with shape (256, 256)
    }
    LinearTorch '4_LinearTorch' with shape (256, 4)
    LIFTorch '5_LIFTorch' with shape (4, 4)
}
2023-11-06 17:42:04,371 - main - INFO - Dropped 193 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 17:42:04,386 - main - INFO - Dropped 193 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:42:04,400 - main - INFO - Dropped 193 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:42:13,448 - main - INFO - Epoch 0 -> Loss:1.3724223789961443, Acc:0.6667073766487542, Best Acc:0.6667073766487542
2023-11-06 17:43:25,476 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 17:43:25,487 - main - INFO - Dropped 188 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:43:25,501 - main - INFO - Dropped 189 output synapses each for 251 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:44:45,517 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 17:44:45,528 - main - INFO - Dropped 191 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:44:45,543 - main - INFO - Dropped 190 output synapses each for 254 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:46:05,820 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 17:46:05,833 - main - INFO - Dropped 191 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:46:05,849 - main - INFO - Dropped 190 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:47:26,021 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 17:47:26,034 - main - INFO - Dropped 192 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:47:26,050 - main - INFO - Dropped 190 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:48:46,289 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 17:48:46,300 - main - INFO - Dropped 192 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:48:46,314 - main - INFO - Dropped 190 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:49:59,505 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 17:49:59,516 - main - INFO - Dropped 192 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:49:59,531 - main - INFO - Dropped 190 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:51:19,843 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 17:51:19,855 - main - INFO - Dropped 192 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:51:19,874 - main - INFO - Dropped 190 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:52:40,111 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 17:52:40,123 - main - INFO - Dropped 192 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:52:40,137 - main - INFO - Dropped 190 output synapses each for 255 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:54:00,556 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 17:54:00,567 - main - INFO - Dropped 192 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:54:00,584 - main - INFO - Dropped 190 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:55:21,352 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 17:55:21,363 - main - INFO - Dropped 192 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:55:21,378 - main - INFO - Dropped 190 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:55:29,437 - main - INFO - Epoch 100 -> Loss:0.24496903497239816, Acc:0.871885686370298, Best Acc:0.9278212017586712
2023-11-06 17:56:41,410 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 17:56:41,421 - main - INFO - Dropped 192 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:56:41,435 - main - INFO - Dropped 190 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:58:01,328 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 17:58:01,341 - main - INFO - Dropped 192 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:58:01,357 - main - INFO - Dropped 190 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:59:21,634 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 17:59:21,645 - main - INFO - Dropped 192 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 17:59:21,667 - main - INFO - Dropped 190 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:00:41,595 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 18:00:41,608 - main - INFO - Dropped 192 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:00:41,625 - main - INFO - Dropped 190 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:02:01,903 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 18:02:01,914 - main - INFO - Dropped 192 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:02:01,929 - main - INFO - Dropped 190 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:03:22,235 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 18:03:22,247 - main - INFO - Dropped 192 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:03:22,261 - main - INFO - Dropped 190 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:04:35,377 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 18:04:35,389 - main - INFO - Dropped 192 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:04:35,403 - main - INFO - Dropped 190 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:05:55,098 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 18:05:55,110 - main - INFO - Dropped 192 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:05:55,124 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:07:14,980 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 18:07:14,991 - main - INFO - Dropped 192 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:07:15,006 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:08:34,760 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 18:08:34,771 - main - INFO - Dropped 192 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:08:34,789 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:08:42,888 - main - INFO - Epoch 200 -> Loss:0.18261475018832996, Acc:0.9158524670249145, Best Acc:0.9353932584269663
2023-11-06 18:09:54,757 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 18:09:54,770 - main - INFO - Dropped 192 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:09:54,786 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:11:14,817 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 18:11:14,831 - main - INFO - Dropped 192 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:11:14,848 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:12:34,692 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 18:12:34,705 - main - INFO - Dropped 192 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:12:34,719 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:13:54,944 - main - INFO - Dropped 137 output synapses each for 12 neurons in layer LinearTorch '0_LinearTorch' with shape (12, 256) (Rec:None)
2023-11-06 18:13:54,956 - main - INFO - Dropped 192 output synapses each for 190 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:13:54,970 - main - INFO - Dropped 191 output synapses each for 256 neurons in layer LinearTorch '0_LinearTorch' with shape (256, 256) (Rec:None)
2023-11-06 18:15:15,008 - main - INFO - Training finished with accuracy: 0.9395456765999023
